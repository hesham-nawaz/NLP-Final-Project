{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJAy9VFL6Z4t",
        "outputId": "6ad51615-0827-4c78-c8b3-caaa36d21e90"
      },
      "outputs": [],
      "source": [
        "# installing appropiate libraries and packages\n",
        "\n",
        "# %pip install pandas\n",
        "# %pip install numpy\n",
        "# %pip install rouge-score\n",
        "# %pip install matplotlib\n",
        "# %pip install scikit-learn\n",
        "# %pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oRWDCpUL6wiN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "import csv\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "import sklearn.decomposition\n",
        "from tqdm import tqdm\n",
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "58c9a9ca6zEb"
      },
      "outputs": [],
      "source": [
        "# loading full dataset in\n",
        "movies = pd.read_csv('rotten_tomatoes_movies.csv')\n",
        "reviews = pd.read_csv('rotten_tomatoes_critic_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yDpSm7GX61wd"
      },
      "outputs": [],
      "source": [
        "# dropping movies that don't have ground truth\n",
        "filteredMovies = movies.dropna(subset = \"critics_consensus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9wnXbv5o63Oq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rotten_tomatoes_link</th>\n",
              "      <th>movie_title</th>\n",
              "      <th>movie_info</th>\n",
              "      <th>critics_consensus</th>\n",
              "      <th>content_rating</th>\n",
              "      <th>genres</th>\n",
              "      <th>directors</th>\n",
              "      <th>authors</th>\n",
              "      <th>actors</th>\n",
              "      <th>original_release_date</th>\n",
              "      <th>...</th>\n",
              "      <th>production_company</th>\n",
              "      <th>tomatometer_status</th>\n",
              "      <th>tomatometer_rating</th>\n",
              "      <th>tomatometer_count</th>\n",
              "      <th>audience_status</th>\n",
              "      <th>audience_rating</th>\n",
              "      <th>audience_count</th>\n",
              "      <th>tomatometer_top_critics_count</th>\n",
              "      <th>tomatometer_fresh_critics_count</th>\n",
              "      <th>tomatometer_rotten_critics_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7533</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Harvard Beats Yale 29-29</td>\n",
              "      <td>In November 1968, undefeated Ivy League footba...</td>\n",
              "      <td>Harvard Beats Yale 29-29 is compelling viewing...</td>\n",
              "      <td>PG</td>\n",
              "      <td>Documentary, Sports &amp; Fitness</td>\n",
              "      <td>Kevin Rafferty</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tommy Lee Jones, Brian Dowling, Vic Gatto, Fra...</td>\n",
              "      <td>2008-09-05</td>\n",
              "      <td>...</td>\n",
              "      <td>Emerging Pictures</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>92.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>Upright</td>\n",
              "      <td>76.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>19</td>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>m/pioneer_2013</td>\n",
              "      <td>Pioneer</td>\n",
              "      <td>The ultimate adventure becomes a nightmare whe...</td>\n",
              "      <td>Pioneer boasts strong acting and a throwback c...</td>\n",
              "      <td>R</td>\n",
              "      <td>Drama, Mystery &amp; Suspense</td>\n",
              "      <td>Erik Skjoldbjaerg</td>\n",
              "      <td>Nikolaj Frobenius, Hans Gunnarsson, Cathinka N...</td>\n",
              "      <td>Wes Bentley, Stephen Lang, Aksel Hennie, Steph...</td>\n",
              "      <td>2014-12-05</td>\n",
              "      <td>...</td>\n",
              "      <td>Magnolia Pictures</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>55.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>Spilled</td>\n",
              "      <td>33.0</td>\n",
              "      <td>423.0</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6983</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>Ghostbusters 2</td>\n",
              "      <td>After saving New York City from a ghost attack...</td>\n",
              "      <td>Thanks to the cast, Ghostbusters 2 is reasonab...</td>\n",
              "      <td>PG</td>\n",
              "      <td>Comedy, Science Fiction &amp; Fantasy</td>\n",
              "      <td>Ivan Reitman</td>\n",
              "      <td>Harold Ramis, Dan Aykroyd</td>\n",
              "      <td>Bill Murray, Dan Aykroyd, Sigourney Weaver, Ha...</td>\n",
              "      <td>1989-06-16</td>\n",
              "      <td>...</td>\n",
              "      <td>Sony Pictures Home Entertainment</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>54.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>Upright</td>\n",
              "      <td>61.0</td>\n",
              "      <td>406948.0</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10459</th>\n",
              "      <td>m/miss_congeniality_2</td>\n",
              "      <td>Miss Congeniality 2 - Armed and Fabulous</td>\n",
              "      <td>Gracie Hart (Sandra Bullock) was never thrille...</td>\n",
              "      <td>Sandra Bullock is still as appealing as ever; ...</td>\n",
              "      <td>PG-13</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>John Pasquin</td>\n",
              "      <td>Marc Lawrence (II), Marc Lawrence</td>\n",
              "      <td>Sandra Bullock, Regina King, William Shatner, ...</td>\n",
              "      <td>2005-03-23</td>\n",
              "      <td>...</td>\n",
              "      <td>Warner Bros.</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>15.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>Spilled</td>\n",
              "      <td>43.0</td>\n",
              "      <td>447190.0</td>\n",
              "      <td>36</td>\n",
              "      <td>22</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2839</th>\n",
              "      <td>m/antonias_line</td>\n",
              "      <td>Antonia (Antonia's Line)</td>\n",
              "      <td>After World War II, Antonia (Willeke van Ammel...</td>\n",
              "      <td>Magical and morbid, Antonia picturesque landsc...</td>\n",
              "      <td>R</td>\n",
              "      <td>Art House &amp; International, Comedy, Drama, Romance</td>\n",
              "      <td>Marleen Gorris</td>\n",
              "      <td>Marleen Gorris</td>\n",
              "      <td>Willeke van Ammelrooy, Els Dottermans, Jan Dec...</td>\n",
              "      <td>1995-09-12</td>\n",
              "      <td>...</td>\n",
              "      <td>BMG</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>67.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Upright</td>\n",
              "      <td>91.0</td>\n",
              "      <td>6224.0</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             rotten_tomatoes_link                               movie_title  \\\n",
              "7533   m/harvard_beats_yale_29_29                  Harvard Beats Yale 29-29   \n",
              "11853              m/pioneer_2013                                   Pioneer   \n",
              "6983             m/ghostbusters_2                            Ghostbusters 2   \n",
              "10459       m/miss_congeniality_2  Miss Congeniality 2 - Armed and Fabulous   \n",
              "2839              m/antonias_line                  Antonia (Antonia's Line)   \n",
              "\n",
              "                                              movie_info  \\\n",
              "7533   In November 1968, undefeated Ivy League footba...   \n",
              "11853  The ultimate adventure becomes a nightmare whe...   \n",
              "6983   After saving New York City from a ghost attack...   \n",
              "10459  Gracie Hart (Sandra Bullock) was never thrille...   \n",
              "2839   After World War II, Antonia (Willeke van Ammel...   \n",
              "\n",
              "                                       critics_consensus content_rating  \\\n",
              "7533   Harvard Beats Yale 29-29 is compelling viewing...             PG   \n",
              "11853  Pioneer boasts strong acting and a throwback c...              R   \n",
              "6983   Thanks to the cast, Ghostbusters 2 is reasonab...             PG   \n",
              "10459  Sandra Bullock is still as appealing as ever; ...          PG-13   \n",
              "2839   Magical and morbid, Antonia picturesque landsc...              R   \n",
              "\n",
              "                                                  genres          directors  \\\n",
              "7533                       Documentary, Sports & Fitness     Kevin Rafferty   \n",
              "11853                          Drama, Mystery & Suspense  Erik Skjoldbjaerg   \n",
              "6983                   Comedy, Science Fiction & Fantasy       Ivan Reitman   \n",
              "10459                                             Comedy       John Pasquin   \n",
              "2839   Art House & International, Comedy, Drama, Romance     Marleen Gorris   \n",
              "\n",
              "                                                 authors  \\\n",
              "7533                                                 NaN   \n",
              "11853  Nikolaj Frobenius, Hans Gunnarsson, Cathinka N...   \n",
              "6983                           Harold Ramis, Dan Aykroyd   \n",
              "10459                  Marc Lawrence (II), Marc Lawrence   \n",
              "2839                                      Marleen Gorris   \n",
              "\n",
              "                                                  actors  \\\n",
              "7533   Tommy Lee Jones, Brian Dowling, Vic Gatto, Fra...   \n",
              "11853  Wes Bentley, Stephen Lang, Aksel Hennie, Steph...   \n",
              "6983   Bill Murray, Dan Aykroyd, Sigourney Weaver, Ha...   \n",
              "10459  Sandra Bullock, Regina King, William Shatner, ...   \n",
              "2839   Willeke van Ammelrooy, Els Dottermans, Jan Dec...   \n",
              "\n",
              "      original_release_date  ...                production_company  \\\n",
              "7533             2008-09-05  ...                 Emerging Pictures   \n",
              "11853            2014-12-05  ...                 Magnolia Pictures   \n",
              "6983             1989-06-16  ...  Sony Pictures Home Entertainment   \n",
              "10459            2005-03-23  ...                      Warner Bros.   \n",
              "2839             1995-09-12  ...                               BMG   \n",
              "\n",
              "       tomatometer_status tomatometer_rating tomatometer_count  \\\n",
              "7533                Fresh               92.0              38.0   \n",
              "11853              Rotten               55.0              44.0   \n",
              "6983               Rotten               54.0              39.0   \n",
              "10459              Rotten               15.0             147.0   \n",
              "2839                Fresh               67.0              49.0   \n",
              "\n",
              "       audience_status  audience_rating audience_count  \\\n",
              "7533           Upright             76.0          553.0   \n",
              "11853          Spilled             33.0          423.0   \n",
              "6983           Upright             61.0       406948.0   \n",
              "10459          Spilled             43.0       447190.0   \n",
              "2839           Upright             91.0         6224.0   \n",
              "\n",
              "       tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
              "7533                              19                               35   \n",
              "11853                             18                               24   \n",
              "6983                               7                               21   \n",
              "10459                             36                               22   \n",
              "2839                              21                               33   \n",
              "\n",
              "       tomatometer_rotten_critics_count  \n",
              "7533                                  3  \n",
              "11853                                20  \n",
              "6983                                 18  \n",
              "10459                               125  \n",
              "2839                                 16  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# parameter: how many movies to conduct the analysis for (CHANGE THIS)\n",
        "to_keep = 5\n",
        "\n",
        "# furtherFilteredMovies = filteredMovies[:to_keep]\n",
        "furtherFilteredMovies= filteredMovies.sample(n = to_keep)\n",
        "furtherFilteredMovies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ivbXUiJz65Yo"
      },
      "outputs": [],
      "source": [
        "movies_to_keep = furtherFilteredMovies[['rotten_tomatoes_link']]\n",
        "\n",
        "# data table for each critic review that has ground truth\n",
        "combined_data = movies_to_keep.merge(reviews, how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ogcC9j0I67up"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rotten_tomatoes_link</th>\n",
              "      <th>critic_name</th>\n",
              "      <th>top_critic</th>\n",
              "      <th>publisher_name</th>\n",
              "      <th>review_type</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>John Anderson</td>\n",
              "      <td>True</td>\n",
              "      <td>Variety</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-09-15</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>New York Magazine/Vulture</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-17</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Paul Brenner</td>\n",
              "      <td>False</td>\n",
              "      <td>Filmcritic.com</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4/5</td>\n",
              "      <td>2008-11-18</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Manohla Dargis</td>\n",
              "      <td>True</td>\n",
              "      <td>New York Times</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4.5/5</td>\n",
              "      <td>2008-11-19</td>\n",
              "      <td>Kevin Rafferty makes the case for remembrance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Kyle Smith</td>\n",
              "      <td>True</td>\n",
              "      <td>New York Post</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>2/4</td>\n",
              "      <td>2008-11-19</td>\n",
              "      <td>The movie, which absurdly tries to paint the H...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         rotten_tomatoes_link     critic_name  top_critic  \\\n",
              "0  m/harvard_beats_yale_29_29   John Anderson        True   \n",
              "1  m/harvard_beats_yale_29_29             NaN        True   \n",
              "2  m/harvard_beats_yale_29_29    Paul Brenner       False   \n",
              "3  m/harvard_beats_yale_29_29  Manohla Dargis        True   \n",
              "4  m/harvard_beats_yale_29_29      Kyle Smith        True   \n",
              "\n",
              "              publisher_name review_type review_score review_date  \\\n",
              "0                    Variety       Fresh          NaN  2008-09-15   \n",
              "1  New York Magazine/Vulture       Fresh          NaN  2008-11-17   \n",
              "2             Filmcritic.com       Fresh          4/5  2008-11-18   \n",
              "3             New York Times       Fresh        4.5/5  2008-11-19   \n",
              "4              New York Post      Rotten          2/4  2008-11-19   \n",
              "\n",
              "                                      review_content  \n",
              "0  How many thrillers could put the outcome in th...  \n",
              "1  This touching, exciting film works less as a c...  \n",
              "2  Ideas were flying around like bullets. And so ...  \n",
              "3  Kevin Rafferty makes the case for remembrance ...  \n",
              "4  The movie, which absurdly tries to paint the H...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sp9aCtRx69aN"
      },
      "outputs": [],
      "source": [
        "# dropping data that don't have review values\n",
        "filtered_combined_data = combined_data.dropna(subset = \"review_content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jlgrSVKW82MQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "\n",
        "def show_similar_words(tokenizer, reps, tokens):\n",
        "    reps = reps / (np.sqrt((reps ** 2).sum(axis=1, keepdims=True)))\n",
        "    #for i, (word, token) in enumerate(tokenizer.word_to_token.items()):\n",
        "    for token in tokens:\n",
        "        word = tokenizer.token_to_word[token]\n",
        "        rep = reps[token, :]\n",
        "        sims = ((reps - rep) ** 2).sum(axis=1)\n",
        "        nearest = np.argsort(sims)\n",
        "        print(word, token)\n",
        "        for j in nearest[1:6]:\n",
        "            print(\" \", tokenizer.token_to_word[j], \"%.3f\" % sims[j])\n",
        "\n",
        "class Tokenizer:\n",
        "  def __init__(self, min_occur=10):\n",
        "    self.word_to_token = {}\n",
        "    self.token_to_word = {}\n",
        "    self.word_count = {}\n",
        "\n",
        "    self.word_to_token['<unk>'] = 0\n",
        "    self.token_to_word[0] = '<unk>'\n",
        "    self.vocab_size = 1\n",
        "\n",
        "    self.min_occur = min_occur\n",
        "\n",
        "  def fit(self, corpus):\n",
        "    for review in corpus:\n",
        "      review = review.strip().lower()\n",
        "      words = re.findall(r\"[\\w']+|[.,!?;]\", review)\n",
        "      for word in words:\n",
        "          if word not in self.word_count:\n",
        "              self.word_count[word] = 0\n",
        "          self.word_count[word] += 1\n",
        "\n",
        "    for review in corpus:\n",
        "      review = review.strip().lower()\n",
        "      words = re.findall(r\"[\\w']+|[.,!?;]\", review)\n",
        "      for word in words:\n",
        "        if self.word_count[word] < self.min_occur:\n",
        "          continue\n",
        "        if word in self.word_to_token:\n",
        "          continue\n",
        "        self.word_to_token[word] = self.vocab_size\n",
        "        self.token_to_word[self.vocab_size] = word\n",
        "        self.vocab_size += 1\n",
        "\n",
        "  def tokenize(self, corpus):\n",
        "    tokenized_corpus = []\n",
        "    for review in corpus:\n",
        "      review = review.strip().lower()\n",
        "      words = re.findall(r\"[\\w']+|[.,!?;]\", review)\n",
        "      tokenized_review = []\n",
        "      for word in words:\n",
        "        if word not in self.word_to_token:\n",
        "          tokenized_review.append(0)\n",
        "        else:\n",
        "          tokenized_review.append(self.word_to_token[word])\n",
        "      tokenized_corpus.append(tokenized_review)\n",
        "    return tokenized_corpus\n",
        "\n",
        "  def de_tokenize(self, tokenized_corpus):\n",
        "    corpus = []\n",
        "    for tokenized_review in tokenized_corpus:\n",
        "      review = []\n",
        "      for token in tokenized_review:\n",
        "        review.append(self.token_to_word[token])\n",
        "      corpus.append(\" \".join(review))\n",
        "    return corpus\n",
        "\n",
        "\n",
        "class CountVectorizer:\n",
        "  def __init__(self, min_occur=10):\n",
        "    self.tokenizer = Tokenizer(min_occur)\n",
        "\n",
        "  def fit(self, corpus):\n",
        "    self.tokenizer.fit(corpus)\n",
        "\n",
        "  def transform(self, corpus):\n",
        "    n = len(corpus)\n",
        "    X = np.zeros((n, self.tokenizer.vocab_size))\n",
        "    for i, review in enumerate(corpus):\n",
        "      review = review.strip().lower()\n",
        "      words = re.findall(r\"[\\w']+|[.,!?;]\", review)\n",
        "      for word in words:\n",
        "        if word not in self.tokenizer.word_count or self.tokenizer.word_count[word] < self.tokenizer.min_occur:\n",
        "          X[i][0] += 1\n",
        "        else:\n",
        "          X[i][self.tokenizer.word_to_token[word]] += 1\n",
        "    return X\n",
        "\n",
        "def get_ngrams(tokenized_corpus, window_size, pad_idx=2006):\n",
        "    ngrams = []\n",
        "    for i, review in enumerate(tokenized_corpus):\n",
        "        for j, word in enumerate(review):\n",
        "            min_ind = max(0, j-window_size)\n",
        "            max_ind = min(len(review), j+window_size+1)\n",
        "            ctx = np.zeros(2 * window_size, dtype=np.int64) + pad_idx\n",
        "            for ik, k in enumerate(range(min_ind, j)):\n",
        "                ctx[ik] = review[k]\n",
        "            for ik, k in enumerate(range(j+1, max_ind)):\n",
        "                ctx[window_size+ik] = review[k]\n",
        "            ngrams.append((ctx, review[j]))\n",
        "    return ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "percent_train = 0.7\n",
        "num_train = int(percent_train*to_keep)\n",
        "\n",
        "# TODO add validation data\n",
        "training_movies, testing_movies = furtherFilteredMovies[:num_train], furtherFilteredMovies[num_train:]\n",
        "\n",
        "training_movies['movie_title']\n",
        "\n",
        "reviews = combined_data[\"review_content\"]\n",
        "rev_type = combined_data[\"review_type\"]\n",
        "labels = rev_type.apply(lambda x: 1 if x == \"Fresh\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data.dropna(subset = [\"review_content\", 'review_type'], inplace=True)\n",
        "\n",
        "train_data = combined_data[combined_data['rotten_tomatoes_link'].isin(training_movies['rotten_tomatoes_link'])]\n",
        "test_data = combined_data[~combined_data['rotten_tomatoes_link'].isin(training_movies['rotten_tomatoes_link'])]\n",
        "\n",
        "train_reviews, train_labels = train_data[\"review_content\"], train_data[\"review_type\"].apply(lambda x: 1 if x == \"Fresh\" else 0)\n",
        "test_reviews, test_labels = test_data[\"review_content\"], test_data[\"review_type\"].apply(lambda x: 1 if x == \"Fresh\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "oS50RXIYU9Tv",
        "outputId": "70a0b2c4-91fb-4a1d-f202-a6426a8bf4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BoW matrix is 105 x 31\n"
          ]
        }
      ],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(train_reviews)\n",
        "train_bow_matrix = vectorizer.transform(train_reviews)\n",
        "test_bow_matrix = vectorizer.transform(test_reviews)\n",
        "print(f\"BoW matrix is {train_bow_matrix.shape[0]} x {train_bow_matrix.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e9p8liIE6_Hg"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "model = gnb.fit(train_bow_matrix, train_labels)\n",
        "\n",
        "test_pred = model.predict(test_bow_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PkUa9eze8qG8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>review_content</th>\n",
              "      <th>review_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Kevin Rafferty makes the case for remembrance ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The movie, which absurdly tries to paint the H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>116</td>\n",
              "      <td>An almost uniformly substandard follow-up that...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>117</td>\n",
              "      <td>The sequel is, on the whole, a fairly mechanic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>118</td>\n",
              "      <td>A rather underwhelming sequel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>119</td>\n",
              "      <td>Murray's in his prime here as one of four fear...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>120</td>\n",
              "      <td>In general, it has the same look and feel, but...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                     review_content  review_type\n",
              "0        0  How many thrillers could put the outcome in th...            1\n",
              "1        1  This touching, exciting film works less as a c...            1\n",
              "2        2  Ideas were flying around like bullets. And so ...            1\n",
              "3        3  Kevin Rafferty makes the case for remembrance ...            1\n",
              "4        4  The movie, which absurdly tries to paint the H...            0\n",
              "..     ...                                                ...          ...\n",
              "100    116  An almost uniformly substandard follow-up that...            0\n",
              "101    117  The sequel is, on the whole, a fairly mechanic...            0\n",
              "102    118                   A rather underwhelming sequel...            1\n",
              "103    119  Murray's in his prime here as one of four fear...            1\n",
              "104    120  In general, it has the same look and feel, but...            1\n",
              "\n",
              "[105 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = pd.DataFrame(train_reviews).reset_index().merge(pd.DataFrame(train_labels).reset_index())\n",
        "test_dataset = pd.DataFrame(test_reviews).reset_index().merge(pd.DataFrame(test_labels).reset_index())\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A sentence']\n",
            "['A sentence', ' Another sentence']\n"
          ]
        }
      ],
      "source": [
        "s1 = \"A sentence\"\n",
        "s2 = \"A sentence. Another sentence.\"\n",
        "\n",
        "def sentence_splitter(s):\n",
        "    return [i for i in s.split(\".\") if i != \"\"]\n",
        "\n",
        "print(sentence_splitter(s1))\n",
        "print(sentence_splitter(s2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset[\"sentences\"] = train_dataset[\"review_content\"].apply(sentence_splitter)\n",
        "train_dataset = train_dataset.explode(\"sentences\")\n",
        "test_dataset[\"sentences\"] = test_dataset[\"review_content\"].apply(sentence_splitter)\n",
        "test_dataset = test_dataset.explode(\"sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data\n",
        "\n",
        "class Word2VecModel(nn.Module):\n",
        "    # A torch module implementing a word2vec predictor. The `forward` function\n",
        "    # should take a batch of context word ids as input and predict the word \n",
        "    # in the middle of the context as output, as in the CBOW model from lecture.\n",
        "    # Hint: look at how padding is handled in lab_util.get_ngrams when\n",
        "    # initializing `ctx`: vocab_size is used as the padding token for contexts\n",
        "    # near the beginning and end of sequences. If you use an embedding module\n",
        "    # in your Word2Vec implementation, make sure to account for this extra\n",
        "    # padding token in the input dimension and include the `padding_idx` kwarg.\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, padding_idx=467):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size+1, embedding_size, padding_idx=padding_idx)\n",
        "        self.linear = nn.Linear(embedding_size, vocab_size)\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, context):\n",
        "        # Context is an `n_batch x n_context` matrix of integer word ids.\n",
        "        # In this case, n_context = 2 * window_size where window_size is defined\n",
        "        # in lab_util.py. This is because each word has both left and right context.\n",
        "        # This function should return an `n_batch x vocab_size` matrix with\n",
        "        # element i, j being the (possibly log) probability of the middle word\n",
        "        # in context i being word j.\n",
        "\n",
        "        return self.softmax(self.linear(torch.mean(self.embeddings(context), axis=1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def learn_reps_word2vec(corpus, window_size, rep_size, n_epochs, n_batch):\n",
        "    # This method takes in a corpus of training sentences. It returns a matrix of\n",
        "    # word embeddings with the same structure as used in the previous section of \n",
        "    # the assignment. (You can extract this matrix from the parameters of the \n",
        "    # Word2VecModel.)\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit(corpus)\n",
        "    tokenized_corpus = tokenizer.tokenize(corpus)\n",
        "\n",
        "    ngrams = get_ngrams(tokenized_corpus, window_size, pad_idx=467)\n",
        "\n",
        "    # device = torch.device('cuda')  # run on colab gpu\n",
        "    model = Word2VecModel(tokenizer.vocab_size, rep_size)\n",
        "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    loader = torch_data.DataLoader(ngrams, batch_size=n_batch, shuffle=True)\n",
        "\n",
        "    # What loss function should we use for Word2Vec?\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()  # Your code here!\n",
        "\n",
        "    losses = []  # Potentially useful for debugging (loss should go down!)\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        epoch_loss = 0\n",
        "        for context, label in loader:\n",
        "            # As described above, `context` is a batch of context word ids, and\n",
        "            # `label` is a batch of predicted word labels.\n",
        "\n",
        "            # Here, perform a forward pass to compute predictions for the model.\n",
        "            # Your code here!\n",
        "            context = context\n",
        "            label = label\n",
        "            preds = model.forward(context)\n",
        "\n",
        "\n",
        "            # Now finish the backward pass and gradient update.\n",
        "            # Remember, you need to compute the loss, zero the gradients\n",
        "            # of the model parameters, perform the backward pass, and\n",
        "            # update the model parameters.\n",
        "            # Your code here!\n",
        "            loss = loss_fn(preds, label)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        losses.append(epoch_loss)\n",
        "\n",
        "    # Hint: you want to return a `vocab_size x embedding_size` numpy array\n",
        "    embedding_matrix = model.linear.weight.cpu().detach().numpy()  # Your code here!\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Padding_idx must be within num_embeddings",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-107-eb2757a41269>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreps_word2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_reps_word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-106-19e51fde91c4>\u001b[0m in \u001b[0;36mlearn_reps_word2vec\u001b[1;34m(corpus, window_size, rep_size, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# device = torch.device('cuda')  # run on colab gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2VecModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-105-615ecf8ea9c9>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab_size, embedding_size, padding_idx)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\ashha\\.julia\\conda\\3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mpadding_idx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Padding_idx must be within num_embeddings'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAssertionError\u001b[0m: Padding_idx must be within num_embeddings"
          ]
        }
      ],
      "source": [
        "reps_word2vec = learn_reps_word2vec(train_dataset[\"sentences\"], 2, 300, 10, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(featurizer, xs, ys):\n",
        "    xs_featurized = featurizer(xs)\n",
        "    model = sklearn.linear_model.LogisticRegression(penalty='none', max_iter=1000)\n",
        "    model.fit(xs_featurized, ys)\n",
        "    return model\n",
        "\n",
        "def eval_model(model, featurizer, xs, ys):\n",
        "    xs_featurized = featurizer(xs)\n",
        "    pred_ys = model.predict(xs_featurized)\n",
        "    return np.mean(pred_ys == ys)\n",
        "\n",
        "def training_experiment(name, featurizer, n_train):\n",
        "    print(f\"{name} features, {n_train} examples\")\n",
        "    train_xs = vectorizer.transform(train_reviews[:n_train])\n",
        "    train_ys = train_labels[:n_train]\n",
        "    test_xs = vectorizer.transform(test_reviews)\n",
        "    test_ys = test_labels\n",
        "    model = train_model(featurizer, train_xs, train_ys)\n",
        "    acc = eval_model(model, featurizer, test_xs, test_ys)\n",
        "    print(acc, '\\n')\n",
        "    return acc\n",
        "\n",
        "def w2v_featurizer(xs):\n",
        "    # This function takes in a matrix in which each row contains the word counts\n",
        "    # for the given review. It should return a matrix in which each row contains\n",
        "    # the average Word2Vec embedding of each review (hint: this will be very\n",
        "    # similar to `lsa_featurizer` from above, just using Word2Vec embeddings \n",
        "    # instead of LSA).\n",
        "\n",
        "    feats = np.matmul(xs, reps_word2vec) # Your code here!\n",
        "\n",
        "    # normalize\n",
        "    return feats / np.sqrt((feats ** 2).sum(axis=1, keepdims=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sentence_mean(sentence):\n",
        "    sentence_list = sentence.split()\n",
        "    cur_total = None\n",
        "    count = 0\n",
        "    for word in sentence_list:\n",
        "        try:\n",
        "            word_vec = wv[word]\n",
        "            if cur_total is None:\n",
        "                cur_total = word_vec\n",
        "            else:\n",
        "                cur_total = np.copy(cur_total) + word_vec\n",
        "            count += 1\n",
        "        except KeyError:\n",
        "            pass\n",
        "    if cur_total is None:\n",
        "        return wv['</s>']\n",
        "    return cur_total/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>review_content</th>\n",
              "      <th>review_type</th>\n",
              "      <th>sentences</th>\n",
              "      <th>sentence_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "      <td>1</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "      <td>[0.025644403, 0.06503778, 0.026081687, 0.11363...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "      <td>1</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "      <td>[-0.008740594, 0.03962977, 0.023433909, 0.0952...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Ideas were flying around like bullets</td>\n",
              "      <td>[0.018697103, 0.098836266, 0.05561574, 0.14388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>1</td>\n",
              "      <td>And so were the footballs</td>\n",
              "      <td>[-0.033984374, 0.06347656, 0.048077393, 0.0577...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Kevin Rafferty makes the case for remembrance ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Kevin Rafferty makes the case for remembrance ...</td>\n",
              "      <td>[0.04748535, 0.06387939, 0.030846024, 0.098077...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>116</td>\n",
              "      <td>An almost uniformly substandard follow-up that...</td>\n",
              "      <td>0</td>\n",
              "      <td>An almost uniformly substandard follow-up that...</td>\n",
              "      <td>[0.02564538, 0.031082816, 0.046438467, 0.05816...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>117</td>\n",
              "      <td>The sequel is, on the whole, a fairly mechanic...</td>\n",
              "      <td>0</td>\n",
              "      <td>The sequel is, on the whole, a fairly mechanic...</td>\n",
              "      <td>[0.0792923, 0.05810547, -0.012290107, 0.079050...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>118</td>\n",
              "      <td>A rather underwhelming sequel...</td>\n",
              "      <td>1</td>\n",
              "      <td>A rather underwhelming sequel</td>\n",
              "      <td>[0.11645508, 0.0501709, 0.034423828, 0.1708374...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>119</td>\n",
              "      <td>Murray's in his prime here as one of four fear...</td>\n",
              "      <td>1</td>\n",
              "      <td>Murray's in his prime here as one of four fear...</td>\n",
              "      <td>[0.062149048, 0.018037276, 0.06344223, 0.07019...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>120</td>\n",
              "      <td>In general, it has the same look and feel, but...</td>\n",
              "      <td>1</td>\n",
              "      <td>In general, it has the same look and feel, but...</td>\n",
              "      <td>[0.0029907227, 0.05899922, 0.037773132, 0.0246...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>139 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                     review_content  review_type  \\\n",
              "0        0  How many thrillers could put the outcome in th...            1   \n",
              "1        1  This touching, exciting film works less as a c...            1   \n",
              "2        2  Ideas were flying around like bullets. And so ...            1   \n",
              "2        2  Ideas were flying around like bullets. And so ...            1   \n",
              "3        3  Kevin Rafferty makes the case for remembrance ...            1   \n",
              "..     ...                                                ...          ...   \n",
              "100    116  An almost uniformly substandard follow-up that...            0   \n",
              "101    117  The sequel is, on the whole, a fairly mechanic...            0   \n",
              "102    118                   A rather underwhelming sequel...            1   \n",
              "103    119  Murray's in his prime here as one of four fear...            1   \n",
              "104    120  In general, it has the same look and feel, but...            1   \n",
              "\n",
              "                                             sentences  \\\n",
              "0    How many thrillers could put the outcome in th...   \n",
              "1    This touching, exciting film works less as a c...   \n",
              "2                Ideas were flying around like bullets   \n",
              "2                            And so were the footballs   \n",
              "3    Kevin Rafferty makes the case for remembrance ...   \n",
              "..                                                 ...   \n",
              "100  An almost uniformly substandard follow-up that...   \n",
              "101  The sequel is, on the whole, a fairly mechanic...   \n",
              "102                      A rather underwhelming sequel   \n",
              "103  Murray's in his prime here as one of four fear...   \n",
              "104  In general, it has the same look and feel, but...   \n",
              "\n",
              "                                          sentence_vec  \n",
              "0    [0.025644403, 0.06503778, 0.026081687, 0.11363...  \n",
              "1    [-0.008740594, 0.03962977, 0.023433909, 0.0952...  \n",
              "2    [0.018697103, 0.098836266, 0.05561574, 0.14388...  \n",
              "2    [-0.033984374, 0.06347656, 0.048077393, 0.0577...  \n",
              "3    [0.04748535, 0.06387939, 0.030846024, 0.098077...  \n",
              "..                                                 ...  \n",
              "100  [0.02564538, 0.031082816, 0.046438467, 0.05816...  \n",
              "101  [0.0792923, 0.05810547, -0.012290107, 0.079050...  \n",
              "102  [0.11645508, 0.0501709, 0.034423828, 0.1708374...  \n",
              "103  [0.062149048, 0.018037276, 0.06344223, 0.07019...  \n",
              "104  [0.0029907227, 0.05899922, 0.037773132, 0.0246...  \n",
              "\n",
              "[139 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[\"sentence_vec\"] = train_dataset[\"sentences\"].apply(sentence_mean)\n",
        "test_dataset[\"sentence_vec\"] = test_dataset[\"sentences\"].apply(sentence_mean)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data[\"sentences\"] = train_data[\"review_content\"].apply(sentence_splitter)\n",
        "train_data = train_data.explode(\"sentences\")\n",
        "test_data[\"sentences\"] = test_data[\"review_content\"].apply(sentence_splitter)\n",
        "test_data = test_data.explode(\"sentences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rotten_tomatoes_link</th>\n",
              "      <th>critic_name</th>\n",
              "      <th>top_critic</th>\n",
              "      <th>publisher_name</th>\n",
              "      <th>review_type</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_content</th>\n",
              "      <th>sentences</th>\n",
              "      <th>sentence_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>John Anderson</td>\n",
              "      <td>True</td>\n",
              "      <td>Variety</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-09-15</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "      <td>How many thrillers could put the outcome in th...</td>\n",
              "      <td>[0.025644403, 0.06503778, 0.026081687, 0.11363...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>New York Magazine/Vulture</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008-11-17</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "      <td>This touching, exciting film works less as a c...</td>\n",
              "      <td>[-0.008740594, 0.03962977, 0.023433909, 0.0952...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Paul Brenner</td>\n",
              "      <td>False</td>\n",
              "      <td>Filmcritic.com</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4/5</td>\n",
              "      <td>2008-11-18</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>Ideas were flying around like bullets</td>\n",
              "      <td>[0.018697103, 0.098836266, 0.05561574, 0.14388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Paul Brenner</td>\n",
              "      <td>False</td>\n",
              "      <td>Filmcritic.com</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4/5</td>\n",
              "      <td>2008-11-18</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>And so were the footballs</td>\n",
              "      <td>[-0.033984374, 0.06347656, 0.048077393, 0.0577...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>m/harvard_beats_yale_29_29</td>\n",
              "      <td>Paul Brenner</td>\n",
              "      <td>False</td>\n",
              "      <td>Filmcritic.com</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4/5</td>\n",
              "      <td>2008-11-18</td>\n",
              "      <td>Ideas were flying around like bullets. And so ...</td>\n",
              "      <td>Ideas were flying around like bullets</td>\n",
              "      <td>[0.018697103, 0.098836266, 0.05561574, 0.14388...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>Tim Brayton</td>\n",
              "      <td>False</td>\n",
              "      <td>Antagony &amp; Ecstasy</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>5/10</td>\n",
              "      <td>2011-05-30</td>\n",
              "      <td>An almost uniformly substandard follow-up that...</td>\n",
              "      <td>An almost uniformly substandard follow-up that...</td>\n",
              "      <td>[0.02564538, 0.031082816, 0.046438467, 0.05816...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>Kathleen Carroll</td>\n",
              "      <td>True</td>\n",
              "      <td>New York Daily News</td>\n",
              "      <td>Rotten</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-06-15</td>\n",
              "      <td>The sequel is, on the whole, a fairly mechanic...</td>\n",
              "      <td>The sequel is, on the whole, a fairly mechanic...</td>\n",
              "      <td>[0.0792923, 0.05810547, -0.012290107, 0.079050...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>David Nusair</td>\n",
              "      <td>False</td>\n",
              "      <td>Reel Film Reviews</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>2.5/4</td>\n",
              "      <td>2016-07-19</td>\n",
              "      <td>A rather underwhelming sequel...</td>\n",
              "      <td>A rather underwhelming sequel</td>\n",
              "      <td>[0.11645508, 0.0501709, 0.034423828, 0.1708374...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>Colette DeDonato</td>\n",
              "      <td>False</td>\n",
              "      <td>Common Sense Media</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>4/5</td>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>Murray's in his prime here as one of four fear...</td>\n",
              "      <td>Murray's in his prime here as one of four fear...</td>\n",
              "      <td>[0.062149048, 0.018037276, 0.06344223, 0.07019...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>m/ghostbusters_2</td>\n",
              "      <td>Mike Massie</td>\n",
              "      <td>False</td>\n",
              "      <td>Gone With The Twins</td>\n",
              "      <td>Fresh</td>\n",
              "      <td>6/10</td>\n",
              "      <td>2020-09-06</td>\n",
              "      <td>In general, it has the same look and feel, but...</td>\n",
              "      <td>In general, it has the same look and feel, but...</td>\n",
              "      <td>[0.0029907227, 0.05899922, 0.037773132, 0.0246...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>427 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           rotten_tomatoes_link       critic_name  top_critic  \\\n",
              "0    m/harvard_beats_yale_29_29     John Anderson        True   \n",
              "1    m/harvard_beats_yale_29_29               NaN        True   \n",
              "2    m/harvard_beats_yale_29_29      Paul Brenner       False   \n",
              "2    m/harvard_beats_yale_29_29      Paul Brenner       False   \n",
              "2    m/harvard_beats_yale_29_29      Paul Brenner       False   \n",
              "..                          ...               ...         ...   \n",
              "116            m/ghostbusters_2       Tim Brayton       False   \n",
              "117            m/ghostbusters_2  Kathleen Carroll        True   \n",
              "118            m/ghostbusters_2      David Nusair       False   \n",
              "119            m/ghostbusters_2  Colette DeDonato       False   \n",
              "120            m/ghostbusters_2       Mike Massie       False   \n",
              "\n",
              "                publisher_name review_type review_score review_date  \\\n",
              "0                      Variety       Fresh          NaN  2008-09-15   \n",
              "1    New York Magazine/Vulture       Fresh          NaN  2008-11-17   \n",
              "2               Filmcritic.com       Fresh          4/5  2008-11-18   \n",
              "2               Filmcritic.com       Fresh          4/5  2008-11-18   \n",
              "2               Filmcritic.com       Fresh          4/5  2008-11-18   \n",
              "..                         ...         ...          ...         ...   \n",
              "116         Antagony & Ecstasy      Rotten         5/10  2011-05-30   \n",
              "117        New York Daily News      Rotten          NaN  2015-06-15   \n",
              "118          Reel Film Reviews       Fresh        2.5/4  2016-07-19   \n",
              "119         Common Sense Media       Fresh          4/5  2017-06-20   \n",
              "120        Gone With The Twins       Fresh         6/10  2020-09-06   \n",
              "\n",
              "                                        review_content  \\\n",
              "0    How many thrillers could put the outcome in th...   \n",
              "1    This touching, exciting film works less as a c...   \n",
              "2    Ideas were flying around like bullets. And so ...   \n",
              "2    Ideas were flying around like bullets. And so ...   \n",
              "2    Ideas were flying around like bullets. And so ...   \n",
              "..                                                 ...   \n",
              "116  An almost uniformly substandard follow-up that...   \n",
              "117  The sequel is, on the whole, a fairly mechanic...   \n",
              "118                   A rather underwhelming sequel...   \n",
              "119  Murray's in his prime here as one of four fear...   \n",
              "120  In general, it has the same look and feel, but...   \n",
              "\n",
              "                                             sentences  \\\n",
              "0    How many thrillers could put the outcome in th...   \n",
              "1    This touching, exciting film works less as a c...   \n",
              "2                Ideas were flying around like bullets   \n",
              "2                            And so were the footballs   \n",
              "2                Ideas were flying around like bullets   \n",
              "..                                                 ...   \n",
              "116  An almost uniformly substandard follow-up that...   \n",
              "117  The sequel is, on the whole, a fairly mechanic...   \n",
              "118                      A rather underwhelming sequel   \n",
              "119  Murray's in his prime here as one of four fear...   \n",
              "120  In general, it has the same look and feel, but...   \n",
              "\n",
              "                                          sentence_vec  \n",
              "0    [0.025644403, 0.06503778, 0.026081687, 0.11363...  \n",
              "1    [-0.008740594, 0.03962977, 0.023433909, 0.0952...  \n",
              "2    [0.018697103, 0.098836266, 0.05561574, 0.14388...  \n",
              "2    [-0.033984374, 0.06347656, 0.048077393, 0.0577...  \n",
              "2    [0.018697103, 0.098836266, 0.05561574, 0.14388...  \n",
              "..                                                 ...  \n",
              "116  [0.02564538, 0.031082816, 0.046438467, 0.05816...  \n",
              "117  [0.0792923, 0.05810547, -0.012290107, 0.079050...  \n",
              "118  [0.11645508, 0.0501709, 0.034423828, 0.1708374...  \n",
              "119  [0.062149048, 0.018037276, 0.06344223, 0.07019...  \n",
              "120  [0.0029907227, 0.05899922, 0.037773132, 0.0246...  \n",
              "\n",
              "[427 rows x 10 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"sentence_vec\"] = train_data[\"sentences\"].apply(sentence_mean)\n",
        "test_data[\"sentence_vec\"] = test_data[\"sentences\"].apply(sentence_mean)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 427/427 [00:03<00:00, 113.71it/s]\n"
          ]
        }
      ],
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "n_rows = train_data.shape[0]\n",
        "graph_matrix = np.zeros((n_rows, n_rows))\n",
        "for i in tqdm(range(n_rows)):\n",
        "    for j in range(i+1, n_rows):\n",
        "        vec1, vec2 = train_data[\"sentence_vec\"].iloc[i], train_data[\"sentence_vec\"].iloc[j]\n",
        "        cos_sim = dot(vec1, vec2)/(norm(vec1)*norm(vec2))\n",
        "        if cos_sim > 0 and cos_sim <= 0.5:\n",
        "            graph_matrix[i][j] = cos_sim\n",
        "            graph_matrix[j][i] = cos_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = n_rows\n",
        "def win(matrix, m, o):\n",
        "    k = 0\n",
        "    for i in range(0, n):\n",
        "        if(matrix[i][m] != 0):\n",
        "            k = k+matrix[i][m]\n",
        "    l = 0\n",
        "    for i in range(0, n):\n",
        "        if(matrix[o][i] != 0):\n",
        "            for j in range(0, n):\n",
        "                if(matrix[j][i] != 0):\n",
        "                    l = l+matrix[j][i]\n",
        "    return float(k/l)\n",
        "  \n",
        "  \n",
        "def wout(matrix, m, o):\n",
        "    k = 0\n",
        "    for i in range(0, n):\n",
        "        if(matrix[0][i] != 0):\n",
        "            k = k+matrix[0][i]\n",
        "    l = 0\n",
        "    for i in range(0, n):\n",
        "        if(matrix[o][i] != 0):\n",
        "            for j in range(0, n):\n",
        "                if(matrix[i][j] != 0):\n",
        "                    l = l+matrix[i][j]\n",
        "    return float(k/l)\n",
        "  \n",
        "  \n",
        "def graphrank(matrix, o, n, p):\n",
        "    a = 0\n",
        "    for i in range(0, n):\n",
        "        if(matrix[i][o] != 0):\n",
        "            k = 0\n",
        "            for s in range(0, n):\n",
        "                if(matrix[i][s] != 0):\n",
        "                    k = k+matrix[i][s]\n",
        "            a = a+float((p[i]/k)*win(matrix, i, o)*wout(matrix, i, o))\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 427/427 [00:00<00:00, 212476.90it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "d = 0.85\n",
        "o = 10\n",
        "p = []\n",
        "  \n",
        "for i in tqdm(range(0, n)):\n",
        "    p.append(1)\n",
        "for k in tqdm(range(0, o)):\n",
        "    for u in tqdm(range(0, n)):\n",
        "        g = graphrank(graph_matrix, u, n, p)\n",
        "        p[u] = (1-d)+d*g\n",
        "for i in tqdm(range(0, n)):\n",
        "    print(\"Page rank of node \", i+1, \"is : \", p[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "3d0356dd31ac549548df25397bd39f5e5849a1d68066be8368804098a4eef64f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
